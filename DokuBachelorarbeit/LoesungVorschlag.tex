%Kapitel des Hauptteils

\chapter{Lösungsideen}  %Name des Kapitels
\label{cha:Lösungsideen} %Label des Kapitels
%TODO Struktur wie??
In diesem Kapitel werden die Lösungsideen für die Umsetzung der im Kapitel \ref{sec:Zielsetzung} definierten Ziele beschreiben.

\section{Programmiersprache/ GUI}
Für die Auswahl der Programmiersprache gibt es viele Auswahlmöglichkeiten. Dennoch wird in dieser Abschlussarbeit die Programmiersprache Python verwendet, da sie die Nötigen Eigenschaften mit sich bringt.\\
%TODO Warum Python? Antworten finden Welche Eingeschaften
Für die Eingabe von Suchdaten, besteht für beide Informationsbeschaffungen die Möglichkeit eine Grafische-Bedienoberfläche oder Konsolen-Eingabe zu verwenden.
\section{Informationsbeschaffung einer ausgewählten Person}	
	\subsection{Wie sieht die Suche nach einer Person im Internet aus?}
	\label{sec:Suche nach Information}
	Die Suche nach einer Person im Internet kann durch mehrere Ansätze erfolgen. Die nachstehenden Ansätze unterscheiden sich in der Art Suche und in dem Umgang der eingeben Daten.
		\subsubsection{Die Art der Personensuche wird anhand den eingegebenen Daten angepasst}
		\label{subsubsec: DieArtderPersonensuchewirdanhanddeneingegebenenDaten angepasst}
		Abhängig von der Anzahl und Art der Daten, die von dem Programm-Anwender eingeben wurden, wird die Art und Reihenfolge der Suche variiert. Die nachfolgenden Fälle sollen diesen Ansatz verdeutlichen.
		
		Im Fall, dass der Vorname, Nachname und Wohnort der gesuchten Person eingegeben wird, kann mit der Hilfe von herkömmlichen Suchmaschinen wie Google, Bing und DuckDuckGo nach Information gesucht werden. Die von den Suchmaschinen vorgeschlagenen Seiten werden anschließend analysiert, interpretiert und gespeichert. Dadurch können weitere Informationen gewonnen werden. Falls Benutzernamen von anderen Webseiten wie Instagram, Facebook oder ähnliches vorgeschlagen werden, kann somit die Suche mit diesen Daten speziell auf den entsprechenden Seiten erweitert werden.
		
		Ein weiterer Fall beschreibt das Szenario, wenn ein Benutzername von der gesuchten Person in das Programm eingegeben wird. Hierbei handelt es sich um einen Benutzernamen von Webseiten wie Facebook, Instagram, usw. Zuallererst, kann hier die entsprechende Webseite nach Informationen zu dem angegebenen Benutzername durchsucht werden. Dadurch können zusätzliche Daten herausgefunden werden, die bei der weiteren Suche von Vorteil wären.
		Nachdem die Webseite nach dem Nutzernamen durchsucht und ausgewertet wurde, kann nun mit herkömmlichen Suchmaschinen die Suche erweitert werden.
		\subsubsection{Es wird unabhängig von den eingegebenen Daten direkt mit einer Suchmaschine nach der Person gesucht}
		Bei diesem Lösungsansatz werden ausschließlich die herkömmlichen Suchmaschinen verwendet. Die Funktion der Suche besteht darin, dass das Programm den vorgeschlagenen Links der Suchmaschinen folgt, wobei die eingegebenen Daten die Art der Suche nicht beeinflussen.
		\subsubsection{Nur ausgewählte Webseiten werden nach einer Person durchsucht}
		Unabhängig von den eingegebenen Daten, werden verschiedene Webseiten durchsucht. Allerdings ohne die Verwendung einer Suchmaschine. Vorschläge für die ausgewählten Webseiten sind Facebook, FuPa, Instagram, Xing, LinkedIn und Twitter.
	
	\subsection{Wann handelt es sich um die gesuchte Person?}
	\label{sec:WannhandeltessichumdiegesuchtePerson}
	Bei jeder einzelnen Suchvariante, besteht die Herausforderung darin, zu erkennen, wann es sich um die gesuchte Person handelt. Durch die große Anzahl an verfügbaren Informationen im Internet, besteht eine hohe Wahrscheinlichkeit, dass Personen mit sehr ähnlichen Profilen gefunden werden. Um diesem Problem entgegen zu wirken, kann die Art der Suche anhand den eingegebene Daten angepasst werden. Dies entspricht dem Ansatz \ref{subsubsec: DieArtderPersonensuchewirdanhanddeneingegebenenDaten angepasst}. Die Suche kann dadurch verfeinert werden und die Anzahl der fehlerhaften Vorschläge wird geringer. Dadurch wird die Wahrscheinlichkeit höher, dass es sich um die richtige Person handelt.\\
	Darüber hinaus kann die Personensuche mit einer Suchmaschine durch verbesserte Suchbefehle ebenfalls verfeinert werden. In dem Buch "'\textit{Open Source Intelligence Techniques}"' \cite{Bazzell}, werden Suchbefehle für bekannte Suchmaschinen aufgezeigt, mit denen die Suche verbessert werden kann. Dies bedeutet, bei einer Personensuche ist es mit den richtigen Suchbefehlen möglich, die Anzahl der Vorschläge um einen großen Teil zu verringern. Ein Beispiel in dem Buch von Michael Bazzell zeigt, wie es funktioniert von 8770 Vorschlägen auf lediglich neun Vorschläge zu reduzieren.\cite{Bazzell} Auch bei dieser Lösungsidee wird die Wahrscheinlichkeit erhöht, dass es sich um die gesuchte Person handelt.\\ Im Fall dass nach diese Maßnahmen dennoch verschiedene Profile angezeigt werden, können die folgenden Erweiterungen in die Suche mit einfließen.
		\subsubsection{Erweiterte Kriterien}
		\label{sec:ErweiterteKriteriern}
		Hierbei handelt es sich um weitere Kriterien, welche die Suche noch mehr eingrenzen sollen. Bekannte Informationen zur Person sollen dazu dienen, die vorgeschlagenen Seiten einer Suchmaschine weiter zu filtern. Genau genommen heißt das, dass das Programm in erster Linie nur die Webseite als Informationsquelle verwendet, die alle Suchbegriffe beinhaltet. Darüber hinaus kann das genaue oder grobe Alter der Zielperson mit in die Suche mit einfließen. Dadurch kann erkannt werden ob der Zeitrahmen des Artikels oder das Erstellungsdatum einer Webseite mit dem Alter der Person übereinstimmt.
		%TODO Erklären wie man Zeitpunkt des Eintrages oder Alter der Webseite erkennen kann.
		\subsubsection{Kontakte der Suchperson werden in Betracht gezogen}	
		Hier kann die Suche erweitert werden, indem auf soziale und berufliche Verbindungen der Zielperson eingegangen wird. Das heißt, dass bekannte Kontakte der gesuchten Person ebenfalls durchsucht und ausgewertet werden. In diesem Fall könnten Facebook-Freunden, FuPa-Teammitglieder, Instagram-Follower oder LinkedIn/Xing-Kontakte als Kontaktquelle dienen. Dadurch können weitere Informationen gewonnen werden, die zur Unterscheidung von Profilen nützlich sein könnten.
		\subsubsection{Profilbilder vergleichen}
		Durch die Google Bildersuche ist es möglich, anstatt einem Suchbegriff ein Bild zu verwenden und nach diesem zu suchen. Dabei kann ein zu suchendes Bild selbst hochgeladen oder ein URL angegeben werden. Bei dem Ergebnis kann es sich um ein ähnliches Bild oder eine Webseite, die das Bild enthält, handeln.\\
		Als Alternative zur Google-Bildersuche kann eine Bilderkennungssoftware verwendet werden um Personen zu identifizieren bzw. zu unterscheiden. %TODO Bilderkennungssoftware suchen
		\subsubsection{Identifikationsschlüssel verwenden}
		Bekannte Information zur Person können als Identifikationsschlüssel verwendetet werden. Allerdings müssen dies einzigartige Daten sein. Dazu zählt die E-Mail-Adresse oder eine Verbindung von mehreren personenbezogene Daten, da der vollständige Name nicht einzigartig ist und sich auf verschiedenen Webseiten unterscheiden kann. Das heißt eine Zielperson kann auf einer Seite einen erfundenen Spitzname und auf der nächsten Seite den vollständigen Namen verwenden. Bei einer einfachen Suche würde das zu Problemen führen.\\
		
		Im Fall das auch mit diese Maßnahmen nicht die gesuchte Person identifiziert werden kann, können mehrere Personenprofile erstellt und angezeigt werde. Der Programm-Anwender kann anschließend aus den vorgeschlagenen Profilen eines auswählen.  
		
	\subsection{Wie wird wichtige Information auf einer Website erkannt?}
	
	Für die Suche einer ausgewählten Person können verschiedenste Arten von Webseiten gefunden werden. Aus diesem Grund muss das Programm eine gewisse "'Intelligenz"' mit sich bringen um die wichtigsten Daten aus einer Seite herauszufiltern. Dabei ist es nicht möglich eine \textit{Hartkodierung} zu verwenden, um festgelegte Bereiche einer Webseite auszulesen.\\
	Die Grundidee zur Lösung diese Problems ist die Analyse des vorliegenden Webseiten-Textes. Eine Methode zur Textanalyse ist die automatisierte Schlüsselwort-Gewinnung. Hierbei wird die HTML-Seite zu einem verwendbaren Text formatiert, wobei die meisten Sonderzeichen herausgefiltert werden. Sonderzeichen wie "'."' und "'@"' werden dabei nicht herausgefiltert, da sie für die E-Mail-Erkennung wichtig sind. Anschließend werden Schlüsselwörter aus dem formatierten Webseitentext generiert. Möglichkeiten zur automatisierten Schlüsselwortgenerierung sind die Verfahren RAKE \ref{sec:RAKE} und die automatisierte Schlüsselwortgenerierung mit Hilfe von Machine Learning \ref{sec:KeywordExtractionMachine Learning}, welche im Laufe dieser Arbeit detailliert beschrieben werden.\\
	Nachdem die Schlüsselwörter generiert und in Listen gespeichert wurden, werden Wortsammlung erstellt. Diese Wortsammlungen sind Listen, welche aussagekräftige Schlüsselwörter enthalten und nach Themen kategorisiert werden. Beispiele für den Inhalt der Listen sind alle Hochschulen und Universitäten in Deutschland, Berufsbezeichnungen/Tätigkeiten, Studiengänge, Hobbys, Städte und Gemeinden in Deutschland.\\
	Mit diesen Wortsammlungen kann nun die Liste mit den bereits generierten Schlüsselwörtern aus dem Webseitentext verglichen werden. Bei einer Übereinstimmung eines Schlüsselwortes wird das Wort mit der entsprechenden Kategorie vorgemerkt und später in die verwendete Speicherstruktur eingetragen. \\
	Die Wortsammlungen werden mit Hilfe von bekannter Listen im Internet eigenständig befüllt. Als Informationsquelle dafür dient jegliche Art von Webseite, die nützliche Information enthält. Dazu zählt auch die Seite \textit{Wikipedia - Die freie Enzyklopädie}.	
		\subsubsection{RAKE}
		\label{sec:RAKE}
		RAKE steht für \textit{Rapid Automatic Keyword Extraction} und stellt eine sehr effiziente Methode zur Schlüsselwortgenerierung dar. Die Funktion von RAKE basiert darin, dass Schlüsselwörter mehrere Wörter mit inhaltlicher Relevanz enthalten können, allerdings selten Stoppwörter \ref{sec:Stoppwörter} und  Sonderzeichen.\cite{rose2010automatic}\\
		Als Stoppwörter werden Wörter bezeichnet, die sehr oft auftreten und keinen großen Informationsgewinn mit sich bringen. Beispiele dafür sind \textit{und}, \textit{weil}, \textit{der} oder \textit{als}.\cite{Stopwords}\\
		
		\begin{figure}[h!]
			\fbox{\parbox{\linewidth}{In einer jungen Wissenschaft wie der Informatik mit ihrer Vielschichtigkeit und ihrer unüberschaubaren Anwendungsvielfalt ist man oftmals noch bestrebt, eine Charakterisierung des Wesens dieser Wissenschaft und Gemeinsamkeiten und Abgrenzungen zu anderen Wissenschaften zu finden. Etablierte Wissenschaften haben es da leichter, sei es, dass sie es aufgegeben haben, sich zu definieren, oder sei es, dass ihre Struktur und ihre Inhalte allgemein bekannt sind.}}
			\caption{Beispieltext}
			\label{fig:text}
		\end{figure}
		
		Zu Beginn wird der zu analysierende Text, hier der Beispieltext in  Bild \ref{fig:text}, durch einen Worttrenner in ein Array, bestehen aus möglichen Schlüsselwörtern, aufgeteilt. Das erzeugte Array wird anschließend in Sequenzen von zusammenhängenden Wörtern unterteilt. Dabei erhalten die Wörter in einer Sequenz die gleiche Position und Reihenfolge wie im Ursprungstext und dienen gemeinsam als Kandidatenschlüsselwort.\cite{rose2010automatic}\\		
		Nachdem die möglichen Schlüsselwörter identifiziert sind, wird für jeden einzelnen Kandidaten einen Score ausgerechnet. Dieser besteht aus dem Quotient des Grades $deg(w)$ und der Häufigkeit $freq(w)$ des Vorkommens eines Wortes innerhalb der Kandidaten. Daraus ergibt sich die Formel:
		\begin{center}
			$deg(w)/freq(w) $
		\end{center}	
		
		Dabei beschreibt der Grad eines Wortes, dass gemeinsame Auftreten mit sich selbst und anderen Schlüsselwörtern. In der Tabelle \ref{tab:Co-occurance} ist der Grad für jedes Wort ablesbar, in dem die Einträge, in der entsprechenden Reihe, summiert werden. Beispielsweise Beträgt der Grad des Wortes "'Wissenschaft"' den Wert \textit{3}. Dies ergibt sich aus der Rechnung:
		\begin{center}
			$2 + 1 = 3$
		\end{center}
		Das Wort "'Wissenschaft"' kommt hier selbst zweimal in dem Kandidaten-Array vor und davon einmal in Verbindung mit dem Worten "'jungen"'. \textit{deg(w)}\\
		Die Häufigkeit des Vorkommens eines Wortes lässt sich ebenfalls in der Tabelle \ref{tab:Co-occurance} ablesen. Allerdings muss hier in der Reihe und Spalte des jeweiligen Wortes nachgeschaut werden. Für das Wort "'Wissenschaft"' beträgt die Häufigkeit des Vorkommens den Wert \textit{3}.\\
		Zusammenfassend kann gesagt werden, dass \textit{deg(w)} die Kandidaten bevorzugt, welche oft und in langen Schlüsselwörtern, die mehrere Wörter enthalten, vorkommen. Dies bedeutet, dass beispielsweise \textit{deg(etabliert)} eine höhere Bewertung als \textit{deg(informatik)} bekommt, obwohl beide Wörter gleich oft im Text vorkommen. Dagegen wird bei \textit{freq(w)}, ausschließlich die Häufigkeit des Vorkommens bewertet. Bei der Formel \textit{deg(w)/freq(w)} werden die Wörter bevorzugt, welche überwiegend in langen Kandidatenwörtern vorkommen. Diese Berechnung bietet dadurch einen guten Mittelweg zur Schlüsselwortgewinnung. Ein Beispiel dafür sind die Wörter \textit{"'Wissenschaften} und \textit{"'allgemein"'}. Hier ist der Quotient von \textit{deg(allgemein)/freq(allgemein)} höher als von \textit{deg(Wissenschaften)/freq(Wissenschaften)}, obwohl die Häufigkeit des Wortes höher ist und der Grad gleich hoch ist. \cite{rose2010automatic}
		%TODO Möglicherweise kann Tabelle mit deg(w), freq(w) und deg(w)/feq(w)
		
		Durch das genannte Verfahren und der Formel \textit{deg(w)/freq(w)} für die Bewertung, ergeben sich die im Bild \ref{fig:SchlüsselwörterMitScore} befindenden Kandidaten mit den dazugehörigem Endbewertungen. \cite{rose2010automatic}
		
		\begin{center}
			\begin{table}[h!]
				\scriptsize
				\begin{tabular}{*{24}{l|}}				
					\rotatebox[origin=c]{90}{} 
					&\rotatebox[origin=c]{90}{wissenschaften} &\rotatebox[origin=c]{90}{wissenschaft} &\rotatebox[origin=c]{90}{sei} &\rotatebox[origin=c]{90}{etablierte} &\rotatebox[origin=c]{90}{informatik} &\rotatebox[origin=c]{90}{aufgegeben} &\rotatebox[origin=c]{90}{gemeinsamkeiten} &\rotatebox[origin=c]{90}{oftmals} &\rotatebox[origin=c]{90}{charakterisierung} &\rotatebox[origin=c]{90}{jungen} &\rotatebox[origin=c]{90}{inhalte} &\rotatebox[origin=c]{90}{allgemein} &\rotatebox[origin=c]{90}{bekannt} &\rotatebox[origin=c]{90}{struktur} &\rotatebox[origin=c]{90}{wesens} &\rotatebox[origin=c]{90}{bestrebt} &\rotatebox[origin=c]{90}{unüberschaubaren} &\rotatebox[origin=c]{90}{anwendungsvielfalt} &\rotatebox[origin=c]{90}{definieren} &\rotatebox[origin=c]{90}{abgrenzungen}
					&\rotatebox[origin=c]{90}{leichter}
					&\rotatebox[origin=c]{90}{finden}
					&\rotatebox[origin=c]{90}{vielschichtigkeit}\\
					\hline
					wissenschaften & 2 & & & 1 & & & & & & & & & & & & & & & & & & &\\
					\hline
					wissenschaft & & 2 & & & & & & & & 1 & & & & & & & & & & & & & \\
					\hline
					sei & & & 1 & & & & & & & & & & & & & & & & & & & &	\\
					\hline
					etablierte & 1 & & &1 & & & & & & & & & & & & & & & & & & &	\\
					\hline
					informatik & & & & &1 & & & & & & & & & & & & & & & & & & \\
					\hline
					aufgegeben & & & & & &1 & & & & & & & & & & & & & & & & &	\\
					\hline
					gemeinsamkeiten & & & & & & & 1& & & & & & & & & & & & & & & &	\\
					\hline
					oftmals & & & & & & & & 1& & & & & & & & & & & & & & &\\
					\hline
					charakterisierung & & & & & & & & & 1& & & & & & & & & & & & & & \\
					\hline
					jungen & & 1 & & & & & & & & 1 & & & & & & & & & & & & &	\\
					\hline
					inhalte & & & & & & & & & & & 1 & 1 & 1 & & & & & & & & & &	\\
					\hline
					allgemein & & & & & & & & & & & 1 & 1 & 1 & & & & & & & & & & \\
					\hline
					bekannt & & & & & & & & & & & 1 & 1 & 1 & & & & & & & & & &	\\
					\hline
					struktur & & & & & & & & & & & & & &1 & & & & & & & & &	\\
					\hline
					wesens & & & & & & & & & & & & & & &1 & & & & & & & &\\
					\hline
					bestrebt & & & & & & & & & & & & & & & & 1& & & & & & & \\
					\hline
					unüberschaubaren & & & & & & & & & & & & & & & & & 1 & 1 & & & & &	\\
					\hline
					anwendungsvielfalt & & & & & & & & & & & & & & & & & 1 & 1 & & & & &	\\
					\hline
					definieren & & & & & & & & & & & & & & & & & & & 1 & & & & \\
					\hline
					abgrenzungen & & & & & & & & & & & & & & & & & & & & 1 & & &	\\
					\hline
					leichter & & & & & & & & & & & & & & & & & & & & & 1 & &	\\
					\hline
					finden & & & & & & & & & & & & & & & & & & & & & & 1 & \\
					\hline
					vielschichtigkeit & & & & & & & & & & & & & & & & & & & & & & & 1	\\
					\hline
				\end{tabular}
				\label{tab:Co-occurance}
				\caption{Co-occurance}
			\end{table}
		\end{center}
	
		\begin{figure}[h!]
			\fbox{\parbox{\linewidth}{ inhalte allgemein bekannt (9.0), unüberschaubaren anwendungsvielfalt (4.0), jungen wissenschaft(3.5), etablierte wissenschaften (3.5), wissenschaften (1.5), wissenschaft (1.5), wesens (1.0), vielschichtigkeit (1.0), struktur (1.0), sei (1.0), oftmals (1.0), leichter (1.0), informatik (1.0), gemeinsamkeiten (1.0), finden (1.0), definieren (1.0), dass (1.0), charakterisierung (1.0), bestrebt (1.0), aufgegeben (1.0), abgrenzungen (1.0)}}
			\caption{Schlüsselwörter mit zugehörigem Score}
			\label{fig:SchlüsselwörterMitScore}
		\end{figure}
	\FloatBarrier
	
		\subsubsection{Automatic Keyword Extraction mit NLP}
		\label{sec:Automatic Keyword Extraction}
		Bei dieser Methode wird der vorliegende Text in die einzelnen Wörter unterteilt. Dabei wird eine Liste mit potentiellen Schlüsselwörtern erstellt, in der \textit{Stoppwörter} und Sonderzeichen herausgefiltert werden. Bei den Schlüsselwörtern handelt es sich nicht ausschließlich um ein Wort sondern auch um Wortsequenzen.\\
		Mit Hilfe von Stemming kann nun die Anzahl der Wörter in der Liste weiter reduziert werden, wodurch eine bessere Schlüsselwortgenerierung möglich ist. \\
		Die Liste mit den möglichen Schlüsselwörtern, kann nach der Häufigkeit des Vorkommens eines Wortes im Text sortiert werden. Das bedeutet, dass das Stammwort, welches am Häufigsten im Text vorkommt, in den folgenden Schritten zuerst verwendet wird. Dadurch kann die Laufzeit der Anwendung verbessert werden.\\
		Mit weiteren Regeln, wie eine Mindestanzahl von Buchstaben in einem Wort, können die Schlüsselwörter weiter begrenzt werden. 
				 
		\subsubsection{Keyword Extraction mit Hilfe von Machine Learning}
		\label{sec:KeywordExtractionMachine Learning}
		In der Theorie ist es möglich, ein Neuronales Netz mit den Begriffen zu trainieren und eine Kategorisierung durchzuführen. Dabei entsteht ein Netz, welches selbst entscheiden würde, in welche Kategorie ein Wort fällt. Das Wort "'Fußball"' müsste dadurch in die Kategorie Hobby eingeordnet werden.
	\subsection{Speicherung der gewonnenen Daten}
	Die gewonnenen Daten können in einem beliebig erweiterbaren Personen-Objekt gespeichert werden. Darüber hinaus lässt sich das Objekt mit bekannten Kontakten der zu suchenden Person erweitern.\\
	Eine andere Möglichkeit wäre die Daten in eine Datei auszulagern. Hierfür wäre eine Datei mit dem Format \textit{CSV} oder \textit{TXT} möglich.
	
\section{Informationsbeschaffung von einer großen Menge unbekannter Personen}
Für die \textit{real-world} Simulation eines Phishing-Mail-Angriffs werden Webseiten mit großen Menge von personenbezogenen Daten benötigt. Möglichkeiten, ausgenommen von den bekannten Social Media Seiten, sind das das Fußballportal FuPa, Xing und LinkedIn.\\
Zum Auslesen der Webseite kann ein Web Scraper erstellt werden, der es ermöglicht die große Menge von Daten auszulesen. Dieser könnte für die entsprechenden Webseiten \textit{hartkodiert} werden. Eine weitere Möglichkeit wäre die Analyse des Webseitentextes, wie bei der Suchfunktion einer ausgewählten Person.

Für die Speicherung der gewonnen Daten kann eine SQL-Datenbank erstellt werden.
Als Alternative kann eine Datei angelegt werden, bei der alle Daten zu allen Personen gut strukturiert gespeichert werden können. Eine Möglichkeit dafür wäre das Dateiformat \textit{CSV} oder \textit{TXT}.
%TODO BILDER von Webseite einfügen für groben Überblick oder in Umsetztung

\section{Generierung der E-Mail-Adressen}
Eine Möglichkeit zur Generierung der E-Mail-Adressen kann das Open Source-Tool von Michael Bazzell \cite{EmailAssumptions} sein, welches mit Hilfe eines automatisierten Webbrowsers verwendet werden kann. Bei diesem Tool werden zuerst über ein Formular, Daten für die E-Mail-Generierung eingetragen. Unter anderem sind das Vorname, Nachname und der E-Mail-Provider. Daraufhin werden die vorgeschlagenen E-Mail-Adressen angezeigt,kopiert und in ein Suchfeld eingefügt. Anschließend kann bei Google, Bing, und Facebook nach Einträgen gesucht und falls ein Eintrag gefunden wurde auch angezeigt werden.

Eine Weitere Möglichkeit wäre ein Algorithmus zu entwickeln, der alle möglichen E-Mail-Adressen aus den Kombinationen von Vorname, Nachname, Geburtsjahr, Benutzernamen und den Domains von den bekanntesten E-Mail-Providern generiert. Dazu gehören \textit{GMX}, \textit{WEB.DE}, \textit{Gmail}, \textit{T-Online}, \textit{Freenet} und \textit{1\&1}.\cite{AnbieterMail} \\
Für den Fall, dass der Arbeitgeber der Zielperson bekannt ist, kann auf der Firmenwebseite nach E-Mail-Adressen gesucht werden. Dadurch ist es möglich die Domain einer Firmen-Mailadresse zu bestimmen und dadurch die Anzahl der zu genierenden Adressen um einen großen Teil zu verringern.\\
Schon bei der Suche von personenbezogenen Daten wird ebenfalls nach E-Mail-Adressen gesucht. Dadurch könnte bereits eine bis jetzt unbekannte Anzahl von Adressen bekannt sein und müssten deswegen nicht mehr generiert werden.

Die erzeugten Adressen werden anschließend auf Validität geprüft. Hierfür gab es früher eine \textit{VRFY} Anfrage von SMTP. Mit dieser Anfrage konnte eine angegebene E-Mail-Adresse überprüft werden. Allerdings wurde der Dienst von Spammern ausgenutzt und wird dadurch von den meisten SMTP-Servern nicht mehr zu Verfügung gestellt.\cite{balduzzi2010abusing}\\
Demnach muss die Validität auf einem anderen Weg geprüft werden. Eine Möglichkeit zur Prüfung ist die Verwendung bereitgestellter Webseiten, bei der die zu prüfenden E-Mail-Adresse angegeben werden kann. Eine anschließende Rückmeldung verrät dann, ob die Adresse verwendet wird oder nicht. Eine Webseite dafür wäre "'\textit{https://centralops.net/co/}"'. Als Alternative dazu, ist die Entwicklung eines Skriptes, welches die Validität der Adresse prüft.

Im Fall, dass mehrere Adressen von diesem Adresspool gültig sind, kann nach mit Hilfe dieser Mail-Adressen nach Einträgen im Internet gesucht werden. Wenn es eine Übereinstimmung mit der Zielperson gibt, wird diese E-Mail ausgewählt. Andernfalls wird an jede gültige Adresse eine Phishing-Mail gesendet. 
%TODO Erwähnen dass facbook nach emails suchen konnte

\section{Erstellung der E-Mail-Muster}
Für die Erstellung der E-Mail-Muster kann eine eigene Klasse erstellt werden, welche für die Erzeugung des Textes zuständig ist. In dieser Klasse werden Strings gespeichert die einem Lückentext ähneln. Abhängig von den gefundenen Daten wird ein Lückentext gewählt, welcher anschließend mit den Daten an den passenden Lücken ergänzt wird. Mit dieser Methode muss jedoch für jede Kombination aus gewonnenen Daten ein Lückentext vorhanden sein.\\
Grundsätzlich können die Muster in zwei große Kategorien unterteilt werden. Es gibt einen privaten und geschäftlichen Teil. Der private Teil hat weiter Unterteilungen wie beispielsweise Familie, Hobby und Interessen. Der Text kann hier in einer Alltagssprache erstellt werden. Für ein geschäftliches Muster sollte eine gehoben Sprache angewendet werden und Daten wie der Firmenname muss bekannt sein. 

\section{Erzeugung der Phishing-Mail}
Es kann abhängig von der gewonnen Information der Person entschieden werden welches Muster gewählt werden soll. Dieser Vorgang läuft automatisch ab.